---
title: "Business Intelligence Project"
author: "Team Champions"
date: "| Date:30/10/2023"
output:
  github_document: 
    toc: yes
    toc_depth: 4
    fig_width: 6
    fig_height: 4
    df_print: default
editor_options:
  chunk_output_type: console
---

# Student Details

|                                              |                  |
|----------------------------------------------|------------------|
| **Student ID Number**                        | 126761           |
|                                              | 134111           |
|                                              | 133996           |
|                                              | 127707           |
|                                              | 135859           |
| **Student Name**                             | Virginia Wanjiru |
|                                              | Immaculate Haayo |
|                                              | Trevor Ngugi     |
|                                              | Clarice Muthoni  |
|                                              | Pauline Wairimu  |
| **BBIT 4.2 Group**                           | B                |
| **BI Project Group Name/ID (if applicable)** | Champions        |

# Setup Chunk

**Note:** the following KnitR options have been set as the global defaults: <BR> `knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE, collapse = FALSE, tidy = TRUE)`.

More KnitR options are documented here <https://bookdown.org/yihui/rmarkdown-cookbook/chunk-options.html> and here <https://yihui.org/knitr/options/>.

#Installing the required packages 
```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(
  warning = FALSE,
  collapse = FALSE
)


# STEP 1. Install and Load the Required Packages ----
## stats ----
if (require("stats")) {
  require("stats")
} else {
  install.packages("stats", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## mlbench ----
if (require("mlbench")) {
  require("mlbench")
} else {
  install.packages("mlbench", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}


## caret ----
if (require("caret")) {
  require("caret")
} else {
  install.packages("caret", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## MASS ----
if (require("MASS")) {
  require("MASS")
} else {
  install.packages("MASS", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## glmnet ----
if (require("glmnet")) {
  require("glmnet")
} else {
  install.packages("glmnet", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## e1071 ----
if (require("e1071")) {
  require("e1071")
} else {
  install.packages("e1071", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## kernlab ----
if (require("kernlab")) {
  require("kernlab")
} else {
  install.packages("kernlab", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## rpart ----
if (require("rpart")) {
  require("rpart")
} else {
  install.packages("rpart", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
```

# Understanding the Structure of Data     

## Loading the Dataset

### Source:

The dataset that was used can be downloaded here: <https://drive.google.com/drive/folders/1-BGEhfOwquXF6KKXwcvrx7WuZXuqmW9q?usp=sharing>

### Reference:

*\
Refer to the APA 7th edition manual for rules on how to cite datasets: <https://apastyle.apa.org/style-grammar-guidelines/references/examples/data-set-references>*

#Linear Regression 
```{r Linear Regression}



# A. Linear Algorithms ----
## 1. Linear Regression ----
### 1.a. Linear Regression using Ordinary Least Squares without caret ----
# The lm() function is in the stats package and creates a linear regression
# model using ordinary least squares (OLS).

#### Load and split the dataset ----
library(readr)
chest_disease <- read_csv("../data/chest_disease.csv")
View(chest_disease)

# Define an 80:20 train:test data split of the dataset.
train_index <- createDataPartition(chest_disease$Outcome,
                                   p = 0.8,
                                   list = FALSE)
chest_disease_train <- chest_disease[train_index, ]
chest_disease_test <- chest_disease[-train_index, ]

#### Train the model ----
chest_disease_model_lm <- lm(Outcome ~ ., chest_disease_train)

#### Display the model's details ----
print(chest_disease_model_lm)

#### Make predictions ----
predictions <- predict(chest_disease_model_lm, chest_disease_test[, 1:8])

#### Display the model's evaluation metrics ----
##### RMSE ----
rmse <- sqrt(mean((chest_disease_test$Outcome - predictions)^2))
print(paste("RMSE =", sprintf(rmse, fmt = "%#.4f")))

##### SSR ----
# SSR is the sum of squared residuals (the sum of squared differences
# between observed and predicted values)
ssr <- sum((chest_disease_test$Outcome - predictions)^2)
print(paste("SSR =", sprintf(ssr, fmt = "%#.4f")))

##### SST ----
# SST is the total sum of squares (the sum of squared differences
# between observed values and their mean)
sst <- sum((chest_disease_test$Outcome - mean(chest_disease_test$Outcome))^2)
print(paste("SST =", sprintf(sst, fmt = "%#.4f")))

##### R Squared ----
# We then use SSR and SST to compute the value of R squared.
# The closer the R squared value is to 1, the better the model.
#sprintf- to determine which format you want your output to be in 

r_squared <- 1 - (ssr / sst)
print(paste("R Squared =", sprintf(r_squared, fmt = "%#.4f")))

##### MAE ----
# MAE is expressed in the same units as the target variable, making it easy to
# interpret. For example, if you are predicting the amount paid in rent,
# and the MAE is KES. 10,000, it means, on average, your model's predictions
# are off by about KES. 10,000.
absolute_errors <- abs(predictions - chest_disease_test$Outcome)
mae <- mean(absolute_errors)
print(paste("MAE =", sprintf(mae, fmt = "%#.4f")))


### 1.b. Linear Regression using Ordinary Least Squares with caret ----
#### Load and split the dataset ----
library(readr)
chest_disease <- read_csv("../data/chest_disease.csv")


# Define an 80:20 train:test data split of the dataset.
train_index <- createDataPartition(chest_disease$Outcome,
                                   p = 0.8,
                                   list = FALSE)
chest_disease_train <- chest_disease[train_index, ]
chest_disease_test <- chest_disease[-train_index, ]

#### Train the model ----
#cv= cross validation resampling method
#lm=linear regression


set.seed(7)
train_control <- trainControl(method = "cv", number = 5)
chest_disease_caret_model_lm <- train(Outcome ~ ., data = chest_disease_train,
                                       method = "lm", metric = "RMSE",
                                       preProcess = c("center", "scale"),
                                       trControl = train_control)

#### Display the model's details ----
print(chest_disease_caret_model_lm)

#### Make predictions ----
predictions <- predict(chest_disease_caret_model_lm,
                       chest_disease_test[, 1:8])

#### Display the model's evaluation metrics ----
##### RMSE ----
rmse <- sqrt(mean((chest_disease_test$Outcome - predictions)^2))
print(paste("RMSE =", sprintf(rmse, fmt = "%#.4f")))

##### SSR ----
# SSR is the sum of squared residuals (the sum of squared differences
# between observed and predicted values)
ssr <- sum((chest_disease_test$Outcome - predictions)^2)
print(paste("SSR =", sprintf(ssr, fmt = "%#.4f")))

##### SST ----
# SST is the total sum of squares (the sum of squared differences
# between observed values and their mean)
sst <- sum((chest_disease_test$Outcome - mean(chest_disease_test$Outcome))^2)
print(paste("SST =", sprintf(sst, fmt = "%#.4f")))

##### R Squared ----
# We then use SSR and SST to compute the value of R squared.
# The closer the R squared value is to 1, the better the model.
#sprintf- to define which format you want your print to be in 

r_squared <- 1 - (ssr / sst)
print(paste("R Squared =", sprintf(r_squared, fmt = "%#.4f")))

##### MAE ----
# MAE is expressed in the same units as the target variable, making it easy to
# interpret. For example, if you are predicting the amount paid in rent,
# and the MAE is KES. 10,000, it means, on average, your model's predictions
# are off by about KES. 10,000.
absolute_errors <- abs(predictions - chest_disease_test$Outcome)
mae <- mean(absolute_errors)
print(paste("MAE =", sprintf(mae, fmt = "%#.4f")))



```
# Logistic Regression without caret
```{r Carry out Logistic Regression}

## 2. Logistic Regression ----
### 2.a. Logistic Regression without caret ----
# The glm() function is in the stats package and creates a
# generalized linear model for regression or classification.
# It can be configured to perform a logistic regression suitable for BINARY
# classification problems.

#### Load and split the dataset ----
library(readr)
chest_disease <- read_csv("../data/chest_disease.csv")



# Define a 70:30 train:test data split of the dataset.
train_index <- createDataPartition(chest_disease$Outcome,
                                   p = 0.7,
                                   list = FALSE)
chest_disease_train <- chest_disease[train_index, ]
chest_disease_test <- chest_disease[-train_index, ]

#### Train the model ----

chest_disease_model_glm <- glm(Outcome ~ ., data = chest_disease_train,
                            family = binomial(link = "logit"))

#### Display the model's details ----
print(chest_disease_model_glm)

#### Make predictions ----
probabilities <- predict(chest_disease_model_glm, chest_disease_test[, 1:8],
                         type = "response")
print(probabilities)
predictions <- ifelse(probabilities > 0.5, "Yes", "No")
print(predictions)

#### Display the model's evaluation metrics ----
table(predictions, chest_disease_test$Outcome)

##Logistic Regression with Caret

library(readr)
chest_disease <- read_csv("../data/chest_disease.csv")
View(chest_disease)

# Define a 70:30 train:test data split of the dataset.
train_index <- createDataPartition(chest_disease$Outcome,
                                   p = 0.7,
                                   list = FALSE)
chest_disease_train <- chest_disease[train_index, ]
chest_disease_test <- chest_disease[-train_index, ]

#### Train the model ----
# We apply the 5-fold cross validation resampling method

train_control <- trainControl(method = "cv", number = 5)
# We can use "regLogistic" instead of "glm"
# Notice the data transformation applied when we call the train function
# in caret, i.e., a standardize data transform (centre + scale)
set.seed(7)

chest_disease_caret_model_logistic <-
  train(Outcome ~ ., data = chest_disease_train,
        method = "glm", metric = "RMSE",
        preProcess = c("center", "scale"), trControl = train_control)

#### Display the model's details ----
print(chest_disease_caret_model_logistic)

#### Make predictions ----
predictions <- predict(chest_disease_caret_model_logistic,
                       chest_disease_test[, 1:8])
predictions<-as.factor(chest_disease_test$Outcome)

#### Display the model's evaluation metrics ----
confusion_matrix <-
  caret::confusionMatrix(predictions,
                         as.factor(chest_disease_test[, 1:9]$Outcome))
print(confusion_matrix)

fourfoldplot(as.table(confusion_matrix), color = c("grey", "lightblue"),
             main = "Confusion Matrix")

# Read the following article on how to compute various evaluation metrics using
# the confusion matrix:
# https://en.wikipedia.org/wiki/Confusion_matrix




```

# LINEAR DICRIMINANT ANALYSIS with caret
```{r Carry out LDA }
## 3. LINEAR DICRIMINANT ANALYSIS ----
### 3.a. Linear Discriminant Analysis without caret ----
# The lda() function is in the MASS package and creates a linear model of a
# multi-class classification problem.

#### Load and split the dataset ----
library(readr)
Crop_recommendation <- read_csv("../data/Crop_recommendation.csv")
View(Crop_recommendation)

# Define a 70:30 train:test data split of the dataset.
train_index <- createDataPartition(Crop_recommendation$label,
                                   p = 0.7,
                                   list = FALSE)
Crop_recommendation_train <- Crop_recommendation[train_index, ]
Crop_recommendation_test <- Crop_recommendation[-train_index, ]

#### Train the model ----
Crop_recommendation_model_lda <- lda(label ~ ., data = Crop_recommendation_train)

#### Display the model's details ----
print(Crop_recommendation_model_lda)


#### Make predictions ----
predictions <- predict(Crop_recommendation_model_lda,
                       Crop_recommendation_test[, 1:7])$class
predictions<-as.factor(Crop_recommendation_test$label)

#### Display the model's evaluation metrics ----
table(predictions, Crop_recommendation_test$label)

# Read the following article on how to compute various evaluation metrics using
# the confusion matrix:
# https://en.wikipedia.org/wiki/Confusion_matrix

### 3.b.  Linear Discriminant Analysis with caret ----
#### Load and split the dataset ----
library(readr)
Crop_recommendation <- read_csv("../data/Crop_recommendation.csv")

# Define a 70:30 train:test data split of the dataset.
train_index <- createDataPartition(Crop_recommendation$label,
                                   p = 0.7,
                                   list = FALSE)
Crop_recommendation_train <- Crop_recommendation[train_index, ]
Crop_recommendation_test <- Crop_recommendation[-train_index, ]

#### Train the model ----
set.seed(7)

# We apply a Leave One Out Cross Validation resampling method
train_control <- trainControl(method = "LOOCV")
# We also apply a standardize data transform to make the mean = 0 and
# standard deviation = 1
Crop_recommendation_caret_model_lda <- train(label ~ .,
                                  data = Crop_recommendation_train,
                                  method = "lda", metric = "Accuracy",
                                  preProcess = c("center", "scale"),
                                  trControl = train_control)

#### Display the model's details ----
print(Crop_recommendation_caret_model_lda)

#### Make predictions ----
predictions<- predict(Crop_recommendation_caret_model_lda,
                       Crop_recommendation_test[, 1:7])

Crop_recommendation_test[, 1:8]$label <- factor(Crop_recommendation_test[, 1:8]$label, levels = levels(predictions))

levels(predictions)
levels(Crop_recommendation_test[, 1:8]$label)



#### Display the model's evaluation metrics ----
library(ggplot2)

# Create a confusion matrix
conf_matrix <- as.table(confusion_matrix)

# Create a heatmap
heatmap <- ggplot(data = data.frame(conf_matrix), aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = 1) +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "Confusion Matrix") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Display the heatmap
print(heatmap)






```



# 4.a. Regularized Linear Regression Classification Problem without CARET ----

```{r Carry Out Regularized Linear Regression Classification Problem without CARET ----}

### 4.a. Regularized Linear Regression Classification Problem without CARET ----
#### Load the dataset ----
library(readr)
chest_disease <- read_csv("../data/chest_disease.csv")
View(chest_disease)


x <- as.matrix(chest_disease[, 1:8])
y <- as.matrix(chest_disease[, 9])

#### Train the model ----
chest_disease_model_glm <- glmnet(x, y, family = "binomial",
                             alpha = 0.5, lambda = 0.001)

#### Display the model's details ----
print(chest_disease_model_glm)

#### Make predictions ----
predictions <- predict(chest_disease_model_glm, x, type = "class")

#### Display the model's evaluation metrics ----
table(predictions, chest_disease$Outcome)


```
# 4.b. Regularized Linear Regression Regression Problem without CARET ----

```{r Carrying out Regularized Linear Regression Regression Problem without CARET ----}
#### Load the dataset ----
library(readr)
chest_disease <- read_csv("../data/chest_disease.csv")
View(chest_disease)


x <- as.matrix(chest_disease[, 1:8])
y <- as.matrix(chest_disease[, 9])

#### Train the model ----
chest_disease_model_glm <- glmnet(x, y, family = "gaussian",
                                   alpha = 0.5, lambda = 0.001)

#### Display the model's details ----
print(chest_disease_model_glm)

#### Make predictions ----
predictions <- predict(chest_disease_model_glm, x, type = "link")

#### Display the model's evaluation metrics ----
mse <- mean((y - predictions)^2)
print(mse)
##### RMSE ----
rmse <- sqrt(mean((y - predictions)^2))
print(paste("RMSE =", sprintf(rmse, fmt = "%#.4f")))

##### SSR ----
ssr <- sum((y - predictions)^2)
print(paste("SSR =", sprintf(ssr, fmt = "%#.4f")))

##### SST ----
sst <- sum((y - mean(y))^2)
print(paste("SST =", sprintf(sst, fmt = "%#.4f")))

##### R Squared ----
r_squared <- 1 - (ssr / sst)
print(paste("R Squared =", sprintf(r_squared, fmt = "%#.4f")))

##### MAE ----
absolute_errors <- abs(predictions - y)
mae <- mean(absolute_errors)
print(paste("MAE =", sprintf(mae, fmt = "%#.4f")))




```

# 4.c. Regularized Linear Regression Classification Problem with CARET ----

```{r 4.c. Regularized Linear Regression Classification Problem with CARET ----}

library(readr)
chest_disease <- read_csv("../data/chest_disease.csv")

# Define a 70:30 train:test data split of the dataset.
train_index <- createDataPartition(chest_disease$Outcome,
                                   p = 0.7,
                                   list = FALSE)
chest_disease_train <- chest_disease[train_index, ]
chest_disease_test <- chest_disease[-train_index, ]

#### Train the model ----
# We apply the 5-fold cross validation resampling method
set.seed(7)
train_control <- trainControl(method = "cv", number = 5)

chest_disease_caret_model_glmnet <-
  train(Outcome ~ ., data = chest_disease_train,
        method = "glmnet", metric = "RMSE",
        preProcess = c("center", "scale"), trControl = train_control)

#### Display the model's details ----
print(chest_disease_caret_model_glmnet)

#### Make predictions ----
predictions <- predict(chest_disease_caret_model_glmnet,
                       chest_disease_test[, 1:8])

# Ensure the levels of predictions and test set Outcome are aligned
predictions <- factor(predictions, levels = levels(chest_disease_test$Outcome))

chest_disease_test$Outcome <- factor(chest_disease_test$Outcome, levels = levels(chest_disease$Outcome))





#### Display the model's evaluation metrics ----
# Specify additional evaluation metrics
eval_metrics <- c("RMSE", "Accuracy", "Precision", "Recall", "F1")



```

#4.d. Regularized Linear Regression Regression Problem with CARET ----

```{r }
### 4.d. Regularized Linear Regression Regression Problem with CARET ----
#### Load and split the dataset ----
library(readr)
chest_disease <- read_csv("../data/chest_disease.csv")
View(chest_disease)

# Define a 70:30 train:test data split of the dataset.
train_index <- createDataPartition(chest_disease$Outcome,
                                   p = 0.7,
                                   list = FALSE)
chest_disease_train <- chest_disease[train_index, ]
chest_disease_test <- chest_disease[-train_index, ]

#### Train the model ----
set.seed(7)
train_control <- trainControl(method = "cv", number = 5)


chest_disease_caret_model_glmnet <-
  train(Outcome ~ .,
        data = chest_disease_train, method = "glmnet",
        metric = "RMSE", preProcess = c("center", "scale"),
        trControl = train_control)


#### Display the model's details ----
print(chest_disease_caret_model_glmnet)

#### Make predictions ----
predictions <- predict(chest_disease_caret_model_glmnet, chest_disease_test[, 1:8])

#### Display the model's evaluation metrics ----
##### RMSE ----
rmse <- sqrt(mean((chest_disease_test$Outcome - predictions)^2))
print(paste("RMSE =", sprintf(rmse, fmt = "%#.4f")))

##### SSR ----
# SSR is the sum of squared residuals (the sum of squared differences
# between observed and predicted values)
ssr <- sum((chest_disease_test$Outcome - predictions)^2)
print(paste("SSR =", sprintf(ssr, fmt = "%#.4f")))

##### SST ----
# SST is the total sum of squares (the sum of squared differences
# between observed values and their mean)
sst <- sum((chest_disease_test$Outcome - mean(chest_disease_test$Outcomel))^2)
print(paste("SST =", sprintf(sst, fmt = "%#.4f")))

##### R Squared ----
# We then use SSR and SST to compute the value of R squared.
# The closer the R squared value is to 1, the better the model.
r_squared <- 1 - (ssr / sst)
print(paste("R Squared =", sprintf(r_squared, fmt = "%#.4f")))

##### MAE ----
# MAE is expressed in the same units as the target variable, making it easy to
# interpret. For example, if you are predicting the amount paid in rent,
# and the MAE is KES. 10,000, it means, on average, your model's predictions
# are off by about KES. 10,000.
# Convert the factors to character for comparison
predictions_char <- as.character(predictions)
actual_outcome_char <- as.character(chest_disease$Outcome)

# Compare the predicted values with the actual values
correct_predictions <- sum(predictions_char == actual_outcome_char)
incorrect_predictions <- sum(predictions_char != actual_outcome_char)

cat("Correct predictions:", correct_predictions, "\n")
cat("Incorrect predictions:", incorrect_predictions, "\n")


mae <- mean(absolute_errors)
print(paste("MAE =", sprintf(mae, fmt = "%#.4f")))





```




