---
title: "Business Intelligence Project"
author: "Team Champions"
date: "| Date:30/10/2023"
output:
  github_document: 
    toc: yes
    toc_depth: 4
    fig_width: 6
    fig_height: 4
    df_print: default
editor_options:
  chunk_output_type: console
---

# Student Details

|                                              |                  |
|----------------------------------------------|------------------|
| **Student ID Number**                        | 126761           |
|                                              | 134111           |
|                                              | 133996           |
|                                              | 127707           |
|                                              | 135859           |
| **Student Name**                             | Virginia Wanjiru |
|                                              | Immaculate Haayo |
|                                              | Trevor Ngugi     |
|                                              | Clarice Muthoni  |
|                                              | Pauline Wairimu  |
| **BBIT 4.2 Group**                           | B                |
| **BI Project Group Name/ID (if applicable)** | Champions        |

# Setup Chunk

**Note:** the following KnitR options have been set as the global defaults: <BR> `knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE, collapse = FALSE, tidy = TRUE)`.

More KnitR options are documented here <https://bookdown.org/yihui/rmarkdown-cookbook/chunk-options.html> and here <https://yihui.org/knitr/options/>.

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(
  warning = FALSE,
  collapse = FALSE
)


# STEP 1. Install and Load the Required Packages ----
## stats ----
if (require("stats")) {
  require("stats")
} else {
  install.packages("stats", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## mlbench ----
if (require("mlbench")) {
  require("mlbench")
} else {
  install.packages("mlbench", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## caret ----
if (require("caret")) {
  require("caret")
} else {
  install.packages("caret", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## MASS ----
if (require("MASS")) {
  require("MASS")
} else {
  install.packages("MASS", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## glmnet ----
if (require("glmnet")) {
  require("glmnet")
} else {
  install.packages("glmnet", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## e1071 ----
if (require("e1071")) {
  require("e1071")
} else {
  install.packages("e1071", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## kernlab ----
if (require("kernlab")) {
  require("kernlab")
} else {
  install.packages("kernlab", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## rpart ----
if (require("rpart")) {
  require("rpart")
} else {
  install.packages("rpart", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
```

# Understanding the Structure of Data     

## Loading the Dataset

### Source:

The dataset that was used can be downloaded here: <https://drive.google.com/drive/folders/1-BGEhfOwquXF6KKXwcvrx7WuZXuqmW9q?usp=sharing>

### Reference:

*\
Refer to the APA 7th edition manual for rules on how to cite datasets: <https://apastyle.apa.org/style-grammar-guidelines/references/examples/data-set-references>*
##### Linear Regression 
```{r Linear Regression}


```
##### Logistic Regression without caret
```{r Carry out Logistic Regression}

## 2. Logistic Regression ----
### 2.a. Logistic Regression without caret ----
# The glm() function is in the stats package and creates a
# generalized linear model for regression or classification.
# It can be configured to perform a logistic regression suitable for BINARY
# classification problems.

#### Load and split the dataset ----
library(readr)
chest_disease <- read_csv("../data/chest_disease.csv")



# Define a 70:30 train:test data split of the dataset.
train_index <- createDataPartition(chest_disease$Outcome,
                                   p = 0.7,
                                   list = FALSE)
chest_disease_train <- chest_disease[train_index, ]
chest_disease_test <- chest_disease[-train_index, ]

#### Train the model ----

chest_disease_model_glm <- glm(Outcome ~ ., data = chest_disease_train,
                            family = binomial(link = "logit"))

#### Display the model's details ----
print(chest_disease_model_glm)

#### Make predictions ----
probabilities <- predict(chest_disease_model_glm, chest_disease_test[, 1:8],
                         type = "response")
print(probabilities)
predictions <- ifelse(probabilities > 0.5, "Yes", "No")
print(predictions)

#### Display the model's evaluation metrics ----
table(predictions, chest_disease_test$Outcome)

# Read the following article on how to compute various evaluation metrics using
# the confusion matrix:
# https://en.wikipedia.org/wiki/Confusion_matrix




```

##### Logistic Regression with caret
```{r Carry out Logistic Regression with caret}

library(readr)
chest_disease <- read_csv("../data/chest_disease.csv")
View(chest_disease)

# Define a 70:30 train:test data split of the dataset.
train_index <- createDataPartition(chest_disease$Outcome,
                                   p = 0.7,
                                   list = FALSE)
chest_disease_train <- chest_disease[train_index, ]
chest_disease_test <- chest_disease[-train_index, ]

#### Train the model ----
# We apply the 5-fold cross validation resampling method

train_control <- trainControl(method = "cv", number = 5)
# We can use "regLogistic" instead of "glm"
# Notice the data transformation applied when we call the train function
# in caret, i.e., a standardize data transform (centre + scale)
set.seed(7)

chest_disease_caret_model_logistic <-
  train(Outcome ~ ., data = chest_disease_train,
        method = "glm", metric = "RMSE",
        preProcess = c("center", "scale"), trControl = train_control)

#### Display the model's details ----
print(chest_disease_caret_model_logistic)

#### Make predictions ----
predictions <- predict(chest_disease_caret_model_logistic,
                       chest_disease_test[, 1:8])
predictions<-as.factor(chest_disease_test$Outcome)

#### Display the model's evaluation metrics ----
confusion_matrix <-
  caret::confusionMatrix(predictions,
                         as.factor(chest_disease_test[, 1:9]$Outcome))
print(confusion_matrix)

fourfoldplot(as.table(confusion_matrix), color = c("grey", "lightblue"),
             main = "Confusion Matrix")

```



# Clustering

```{r Carry Out Clustering}




```
# Association

```{r Carrying out association}




```


